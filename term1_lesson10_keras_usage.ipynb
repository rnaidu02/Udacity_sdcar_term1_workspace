{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras API usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 6s - loss: 1.1520 - acc: 0.4000 - val_loss: 0.7598 - val_acc: 0.6500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s - loss: 0.7641 - acc: 0.6250 - val_loss: 0.6178 - val_acc: 0.7500\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s - loss: 0.6042 - acc: 0.8500 - val_loss: 0.4362 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('data/small_traffic_set/small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "# TODO: Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "#2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(128))\n",
    "#3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "#4th Layer - Add a fully connected layer\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 8s - loss: 1.3829 - acc: 0.2375 - val_loss: 0.7829 - val_acc: 0.6500\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s - loss: 0.8443 - acc: 0.5375 - val_loss: 0.4857 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s - loss: 0.5461 - acc: 0.8250 - val_loss: 0.3883 - val_acc: 0.8500\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s - loss: 0.4579 - acc: 0.8125 - val_loss: 0.2669 - val_acc: 0.8500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s - loss: 0.3636 - acc: 0.8000 - val_loss: 0.2174 - val_acc: 0.8500\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s - loss: 0.2832 - acc: 0.8500 - val_loss: 0.1885 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s - loss: 0.2938 - acc: 0.8250 - val_loss: 0.1732 - val_acc: 0.8500\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s - loss: 0.3107 - acc: 0.8125 - val_loss: 0.1750 - val_acc: 0.8500\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s - loss: 0.2463 - acc: 0.8875 - val_loss: 0.1875 - val_acc: 0.8500\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s - loss: 0.2292 - acc: 0.8500 - val_loss: 0.1439 - val_acc: 0.9500\n",
      "Testing\n",
      "loss: 0.23982709646224976\n",
      "acc: 0.8500000238418579\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "with open('data/small_traffic_set/small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# TODO: Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3,\n",
    "                activation='relu',\n",
    "                input_shape=(32, 32, 3),\n",
    "                border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(128))\n",
    "#3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "#4th Layer - Add a fully connected layer\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=10, validation_split=0.2)\n",
    "\n",
    "# Validation code\n",
    "with open('data/small_traffic_set/small_test_traffic.p', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "# TODO: Evaluate the test data in Keras Here\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test, verbose=0)\n",
    "# TODO: UNCOMMENT CODE\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Cifar-10 data with the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "35000/35000 [==============================] - 5s - loss: 1.4539 - acc: 0.4863 - val_loss: 10.7803 - val_acc: 0.3269\n",
      "Epoch 2/10\n",
      "35000/35000 [==============================] - 5s - loss: 1.2022 - acc: 0.5749 - val_loss: 10.2760 - val_acc: 0.3590\n",
      "Epoch 3/10\n",
      "35000/35000 [==============================] - 5s - loss: 1.0732 - acc: 0.6186 - val_loss: 10.6211 - val_acc: 0.3373\n",
      "Epoch 4/10\n",
      "35000/35000 [==============================] - 5s - loss: 0.9844 - acc: 0.6508 - val_loss: 10.4886 - val_acc: 0.3451 - loss: 0.9834 - acc: 0.65 - ETA: 0s - loss: 0.9833 - a\n",
      "Epoch 5/10\n",
      "35000/35000 [==============================] - 5s - loss: 0.9066 - acc: 0.6797 - val_loss: 10.1632 - val_acc: 0.3657\n",
      "Epoch 6/10\n",
      "35000/35000 [==============================] - 5s - loss: 0.8379 - acc: 0.7055 - val_loss: 10.3906 - val_acc: 0.3512\n",
      "Epoch 7/10\n",
      "35000/35000 [==============================] - 5s - loss: 0.7809 - acc: 0.7231 - val_loss: 9.4929 - val_acc: 0.4060\n",
      "Epoch 8/10\n",
      "35000/35000 [==============================] - 5s - loss: 0.7321 - acc: 0.7399 - val_loss: 10.9076 - val_acc: 0.3202\n",
      "Epoch 9/10\n",
      "35000/35000 [==============================] - 5s - loss: 0.6837 - acc: 0.7538 - val_loss: 9.9615 - val_acc: 0.37890.753\n",
      "Epoch 10/10\n",
      "35000/35000 [==============================] - 5s - loss: 0.6406 - acc: 0.7724 - val_loss: 10.3477 - val_acc: 0.3551\n",
      "Testing\n",
      "loss: 1.061472832107544\n",
      "acc: 0.6507\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "'''\n",
    "with open('data/small_traffic_set/small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "'''\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify = y_train)\n",
    "# y_train.shape is 2d, (50000, 1). While Keras is smart enough to handle this\n",
    "# it's a good idea to flatten the array.\n",
    "\n",
    "#y_train = y_train.reshape(-1)\n",
    "#y_valid = y_valid.reshape(-1)\n",
    "#y_test = y_test.reshape(-1)\n",
    "\n",
    "# TODO: Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3,\n",
    "                activation='relu',\n",
    "                input_shape=(32, 32, 3),\n",
    "                border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(128))\n",
    "#3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "#4th Layer - Add a fully connected layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_valid_one_hot = label_binarizer.fit_transform(y_valid)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "# TODO: change the number of training epochs to 3\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=10, validation_data=(X_valid, y_valid_one_hot))\n",
    "\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "# TODO: Evaluate the test data in Keras Here\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test, verbose=0)\n",
    "# TODO: UNCOMMENT CODE\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
